{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c58c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b851c63f",
   "metadata": {},
   "source": [
    "# Function to rescale each frame from the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b33b1538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_frame(frame,scale):\n",
    "    width = int(frame.shape[1] * scale) #getting current width of the frame and scaling it to the value provided\n",
    "    height = int(frame.shape[0] * scale) #getting current height of the frame scaling it to the value provided\n",
    "    dimensions = (width-100, height) #reducing 100units form the current width and creating a dimensions tuple\n",
    "    return cv2.resize(frame, dimensions, interpolation=cv2.INTER_AREA) #passing the current frame, new dimensions tuple in resize function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf353a5",
   "metadata": {},
   "source": [
    "# Loading the 'Haarcascade' file which will be used as the face detection algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23364805",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade=cv2.CascadeClassifier(\"cascades/haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbd11c4",
   "metadata": {},
   "source": [
    "# Loading the model used for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1e96c0",
   "metadata": {},
   "source": [
    "Changes were made to the network, tested on the test dataset and confusion matrix were generated for each model's predictions for the test data. The model with the most balanced confusin matrix was chosen to be the model of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0dd38f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('model/face_mask_detection_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd652b99",
   "metadata": {},
   "source": [
    "# A function to to predict for each frame and convert the neumeric results to its respective class name, confidence etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7033980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(image):\n",
    "\n",
    "    frame_exp = np.expand_dims(image,axis=0) #increasing the image dimension to fit the dimension used while training\n",
    "    pred_ = model.predict(x=frame_exp) #preicting the class\n",
    "    norm_pred = np.argmax(pred_) #recieving the index of the class with the highest confidence value\n",
    "    conf =\"{:.2f}\".format(np.max(pred_)*100) #formatting the confidence value\n",
    "    \n",
    "    #if prediction is 0 the classname will be 'Mask'\n",
    "    if norm_pred==0:\n",
    "        pred = 'Mask'\n",
    "        addX = 230 #values for defining the rectangle around the classname text\n",
    "        color=(0,255,0) #color of the rectangle\n",
    "\n",
    "    #if prediction is 1 the classname will be 'Non Mask'\n",
    "    else:\n",
    "        pred = 'Non Mask'\n",
    "        addX = 300\n",
    "        color=(0,0,255)\n",
    "    \n",
    "    return pred,conf,color,addX        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c59ce01",
   "metadata": {},
   "source": [
    "# Capturing video from the webcam and performing the detection and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe233811",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 227\n",
    "video=cv2.VideoCapture(0)\n",
    "address = 'http://192.168.0.4:8080//video'\n",
    "video.open(address)\n",
    "\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        check,frame=video.read() #reading the video from the webcam\n",
    "        frame_resized = cv2.resize(frame,(IMG_SIZE,IMG_SIZE)) #resizing the frame to the image size used in the model (227,227)\n",
    "        frame_rescaled = rescale_frame(frame,0.5) #rescaling the frame using the function defined\n",
    "        gray_frame = cv2.cvtColor(frame_rescaled,cv2.COLOR_BGR2GRAY) #converting the frame to gray for haarcascase face detection\n",
    "        faces = face_cascade.detectMultiScale(gray_frame,scaleFactor=1.5,minNeighbors=5) #passung the gray_frame to haarcascade's detection method\n",
    "\n",
    "        for x,y,w,h in faces: #interating over each frame and recieving the 4 points of the bounded region where the face is\n",
    "            roi_gray = gray_frame[y:y+h,x:x+w] #defining the 4 points where the face exists for gray_frame\n",
    "            roi_color = frame_rescaled[y:y+h,x:x+w] #defining the 4 points where the face exists for color_frame\n",
    "            \n",
    "            stroke = 2 #defining the stroke size for drawing the rectangle on the detected face\n",
    "            end_cord_x = x+w #end coordinate of the width of the rectangle\n",
    "            end_cord_y = y+h #end coordinate for the height of the rectangle\n",
    "            \n",
    "            face_only = cv2.resize(roi_color,(IMG_SIZE,IMG_SIZE)) #grabbing only the detected face, resizing it to (227,227)\n",
    "            pred,conf,color,addX = predictions(face_only) #passing the face part to prediction function to get the predicted class\n",
    "            \n",
    "            cv2.rectangle(frame_rescaled,(x,y),(end_cord_x,end_cord_y),color,stroke) #drawing the rectangle using the start and end coordinates on the live video\n",
    "            \n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX #defining the font style\n",
    "            text = pred+':'+conf+'%' #defining the text to be shown\n",
    "            stroke = 2 #defining the stroke size\n",
    "            \n",
    "            cv2.rectangle(frame_rescaled,(x,y-40),(x+addX,y),color,cv2.FILLED) #drawing a rectange arountd the text\n",
    "            cv2.putText(frame_rescaled,text,(x,y-10),font,1,(255,255,255),stroke) #writing the prediction and confidence on the frame\n",
    "\n",
    "        cv2.imshow('webcam',frame_rescaled) #show the webcam video\n",
    "        key=cv2.waitKey(1)\n",
    "\n",
    "        if key==ord('w'):\n",
    "            break   \n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        break\n",
    "        \n",
    "video.release()\n",
    "cv2.destroyWindow('webcam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127a59b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
